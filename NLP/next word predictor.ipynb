{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d53db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b6aa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset copied to: E:\\github\\data science\\data-science\\NLP\\next-word-predictor-text-generator-dataset\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Download dataset from Kaggle\n",
    "path = kagglehub.dataset_download(\"ashishpandey2062/next-word-predictor-text-generator-dataset\")\n",
    "\n",
    "# Destination path\n",
    "dest_path = r\"E:\\github\\data science\\data-science\\NLP\\next-word-predictor-text-generator-dataset\"\n",
    "\n",
    "# Copy everything from KaggleHub's cache to your chosen folder\n",
    "if not os.path.exists(dest_path):\n",
    "    os.makedirs(dest_path)\n",
    "\n",
    "for item in os.listdir(path):\n",
    "    s = os.path.join(path, item)\n",
    "    d = os.path.join(dest_path, item)\n",
    "    if os.path.isdir(s):\n",
    "        shutil.copytree(s, d, dirs_exist_ok=True)\n",
    "    else:\n",
    "        shutil.copy2(s, d)\n",
    "\n",
    "print(\"Dataset copied to:\", dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0303dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sun was shining brightly in the clear blue sky, and a gentle breeze rustled the leaves of the tall trees. people were out enjoying the beautiful weather, some sitting in the park, others taking a leisurely stroll along the riverbank. children were playing games, and laughter filled the air.\n",
      "\n",
      "as the day turned into evening, the temperature started to drop, and the sky transformed into a canvas of vibrant colors. families gathered for picnics, and the smell of barbecues wafted through the air.\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"E:\\github\\data science\\data-science\\NLP\\next-word-predictor-text-generator-dataset\\next_word_predictor.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "    text_data=text_data.lower()\n",
    "print(text_data[:500])  # show first 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87feb39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 tokens: ['the', 'sun', 'was', 'shining', 'brightly', 'in', 'the', 'clear', 'blue', 'sky', ',', 'and', 'a', 'gentle', 'breeze', 'rustled', 'the', 'leaves', 'of', 'the', 'tall', 'trees', '.']\n",
      "Sentence 2 tokens: ['people', 'were', 'out', 'enjoying', 'the', 'beautiful', 'weather', ',', 'some', 'sitting', 'in', 'the', 'park', ',', 'others', 'taking', 'a', 'leisurely', 'stroll', 'along', 'the', 'riverbank', '.']\n",
      "Sentence 3 tokens: ['children', 'were', 'playing', 'games', ',', 'and', 'laughter', 'filled', 'the', 'air', '.']\n",
      "Sentence 4 tokens: ['as', 'the', 'day', 'turned', 'into', 'evening', ',', 'the', 'temperature', 'started', 'to', 'drop', ',', 'and', 'the', 'sky', 'transformed', 'into', 'a', 'canvas', 'of', 'vibrant', 'colors', '.']\n",
      "Sentence 5 tokens: ['families', 'gathered', 'for', 'picnics', ',', 'and', 'the', 'smell', 'of', 'barbecues', 'wafted', 'through', 'the', 'air', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "nltk.download('punkt')          # sentence + word tokenizer\n",
    "nltk.download('punkt_tab')     \n",
    "sent=sent_tokenize(text_data)\n",
    "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sent]\n",
    "\n",
    "for i, tokens in enumerate(tokenized_sentences[:5]):\n",
    "    print(f\"Sentence {i+1} tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9be3e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: ['the', 'sun', 'was', 'shining', 'brightly', 'in', 'the', 'clear', 'blue', 'sky', ',', 'and', 'a', 'gentle', 'breeze', 'rustled', 'the', 'leaves', 'of', 'the', 'tall', 'trees', '.', 'people', 'were', 'out', 'enjoying', 'the', 'beautiful', 'weather']\n"
     ]
    }
   ],
   "source": [
    "all_words=[word for sen in tokenized_sentences for word in sen]\n",
    "print(f\"Total words: {all_words[:30]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eefc0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5054\n",
      "First 10 word2idx mappings: {',': 1, '.': 2, 'the': 3, ':': 4, 'and': 5, 'a': 6, 'of': 7, 'to': 8, 'i': 9, 'you': 10}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "word_count=Counter(all_words)\n",
    "vocab=sorted(word_count,key=word_count.get,reverse=True)\n",
    "word2idx={word:idx+1 for idx,word in enumerate(vocab)}\n",
    "idx2word={idx:word for word,idx in word2idx.items()}\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "print(\"First 10 word2idx mappings:\", dict(list(word2idx.items())[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a6b6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedsen=[[word2idx[word] for word in sen] for sen in tokenized_sentences]\n",
    "x=[]\n",
    "y=[]\n",
    "for i in encodedsen:\n",
    "    for j in range(1,len(i)):\n",
    "        x.append(i[:j])\n",
    "        y.append(i[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "793909e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([33359, 86])\n",
      "Target shape: torch.Size([33359])\n"
     ]
    }
   ],
   "source": [
    "x=[torch.tensor(i) for i in x]\n",
    "y=torch.tensor(y)\n",
    "x=pad_sequence(x,batch_first=True)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "874a718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nextword(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,hidden_dim):\n",
    "        super(nextword,self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab_size+1,embedding_dim,padding_idx=0)\n",
    "        self.lstm=nn.LSTM(embedding_dim,hidden_dim,batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_dim,vocab_size+1)\n",
    "    def forward(self,x):\n",
    "        x=self.embedding(x)\n",
    "        x,_=self.lstm(x)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b492dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output shape: torch.Size([32, 10, 5055])\n"
     ]
    }
   ],
   "source": [
    "model=nextword(len(word2idx),100,128)\n",
    "sample=torch.randint(0,len(word2idx),(32,10))\n",
    "output=model(sample)\n",
    "print(\"Sample output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adefc050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = model.embedding(x)\n",
    "# x, _ = model.lstm(x)\n",
    "# x = model.fc(x[:, -1, :])\n",
    "# x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e6eb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "dataset= TensorDataset(x,y)\n",
    "train_size=int(0.8 * len(dataset))\n",
    "val_size=len(dataset)-train_size\n",
    "train_ds,val_ds=torch.utils.data.random_split(dataset,[train_size,val_size])\n",
    "train_loader=DataLoader(train_ds,batch_size=32,shuffle=True)\n",
    "val_loader=DataLoader(val_ds,batch_size=32)\n",
    "\n",
    "import torch.optim as optim\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbcad450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 6.6157\n",
      "Epoch 2/10, Loss: 6.2915\n",
      "Epoch 3/10, Loss: 6.2705\n",
      "Epoch 4/10, Loss: 6.2650\n",
      "Epoch 5/10, Loss: 6.2630\n",
      "Epoch 6/10, Loss: 6.2601\n",
      "Epoch 7/10, Loss: 6.2583\n",
      "Epoch 8/10, Loss: 6.2569\n",
      "Epoch 9/10, Loss: 6.2548\n",
      "Epoch 10/10, Loss: 6.2541\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for input,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output=model(input)\n",
    "        output=output[:,-1,:]\n",
    "        loss=criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.item()\n",
    "    avg_loss=total_loss/len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d414104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.9445\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss=0\n",
    "with torch.no_grad():\n",
    "    for input,labels in val_loader:\n",
    "        output=model(input)\n",
    "        output=output[:,-1,:]\n",
    "        loss=criterion(output,labels)\n",
    "        val_loss+=loss.item()\n",
    "print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce83af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, text, word2idx, idx2word, top_k=5):\n",
    "    model.eval()\n",
    "    tokens = [word2idx[w] for w in text.lower().split() if w in word2idx]\n",
    "    input_seq = torch.tensor(tokens).unsqueeze(0) # batch=1\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(input_seq)[:, -1, :]   # last timestep\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            top_probs, top_idxs = probs.topk(top_k)\n",
    "    return [idx2word[idx.item()] for idx in top_idxs[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b913eb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', ':', 'the', 'and']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_13688\\3143486604.py:6: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "c:\\Python312\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(predict_next_word(model, \n",
    "      \"As the stars began to twinkle in the night sky, the crowd\", \n",
    "      word2idx, idx2word))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
